{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04973ddf",
   "metadata": {},
   "source": [
    "## Stemming "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b2ffd5",
   "metadata": {},
   "source": [
    "Stemming in NLP is a text normalization technique that chops off word endings (suffixes/prefixes) to reduce words to their base or \"stem\" form, like turning \"running,\" \"runs,\" \"ran\" into \"run,\" helping to group related words for tasks like search, classification, and analysis by simplifying text and improving efficiency, though the resulting stem might not always be a real word (e.g., \"arguing\" to \"argu\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e655fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"running\", \"runs\", \"runner\", \"easily\", \"fairly\",\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b7bb6c",
   "metadata": {},
   "source": [
    "### Implementing PorterStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73055f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "por_stem=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94a04e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running----->run\n",
      "runs----->run\n",
      "runner----->runner\n",
      "easily----->easili\n",
      "fairly----->fairli\n",
      "eating----->eat\n",
      "eats----->eat\n",
      "eaten----->eaten\n",
      "writing----->write\n",
      "writes----->write\n",
      "programming----->program\n",
      "programs----->program\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"----->\"+por_stem.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5162a928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'misuderstand'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "por_stem.stem(\"misuderstanding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35285aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "por_stem.stem(\"congratulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc19187e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wellb'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "por_stem.stem(\"wellbeing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e7da1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chase'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "por_stem.stem(\"chasing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc085b3",
   "metadata": {},
   "source": [
    "## Implementing RegexpStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fd404a",
   "metadata": {},
   "source": [
    "A stemmer that uses regular expressions to identify morphological affixes. Any substrings that match the regular expressions will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6e9cbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "reg_stem=RegexpStemmer('ing$|s$|e$|able$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ca78734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sleep'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stem.stem('sleeping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90c92c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sleep'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stem.stem('sleep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b948eb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Count'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stem.stem('Countable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe09a8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stem.stem('runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "655e7d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'non-negoti'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stem.stem('non-negotiable')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa969fc",
   "metadata": {},
   "source": [
    "### Implementing SnowballStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8156b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball_stem=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45516d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running---->run\n",
      "runs---->run\n",
      "runner---->runner\n",
      "easily---->easili\n",
      "fairly---->fair\n",
      "eating---->eat\n",
      "eats---->eat\n",
      "eaten---->eaten\n",
      "writing---->write\n",
      "writes---->write\n",
      "programming---->program\n",
      "programs---->program\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"---->\"+snowball_stem.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cfd92c",
   "metadata": {},
   "source": [
    "## Comparing porterStemmer and  snowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "288bfd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('easili', 'success', 'fairli')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "por_stem.stem('easily'),por_stem.stem('successfully'),por_stem.stem(\"fairly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c724c834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('easili', 'success', 'fair')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball_stem.stem('easily'),snowball_stem.stem('successfully'),snowball_stem.stem(\"fairly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0dfdee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "por_stem.stem('congratulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be339ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball_stem.stem('congratulations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344d5d8f",
   "metadata": {},
   "source": [
    "Because in regexp it has parameter includes suffix \"s\"\n",
    "\n",
    "\n",
    "reg_stem=RegexpStemmer('ing$|s$|e$|able$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "efdcda64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratulation'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stem.stem('congratulations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2260d4dd",
   "metadata": {},
   "source": [
    "## Implementing Lancaster Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec782029",
   "metadata": {},
   "source": [
    "It uses an iterative approach, and this makes it the most aggressive algorithm among the three stemmers described in this article. Due to its iterative approach, it may lead to over-stemming, which may result in the linguistically incorrect roots. It is not as efficient as a porter or snowball stemmer. Also, it only supports the English language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f29b0185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "lan_stem=LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9099c2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running------->run\n",
      "runs------->run\n",
      "runner------->run\n",
      "easily------->easy\n",
      "fairly------->fair\n",
      "eating------->eat\n",
      "eats------->eat\n",
      "eaten------->eat\n",
      "writing------->writ\n",
      "writes------->writ\n",
      "programming------->program\n",
      "programs------->program\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"------->\"+lan_stem.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c8d4f3",
   "metadata": {},
   "source": [
    "It leads to linguistic incorrect results, due to its aggressive approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86336686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2719d4dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd32cea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
